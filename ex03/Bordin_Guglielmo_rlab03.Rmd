---
title: R Laboratory – Exercise 3
author: Guglielmo Bordin
date: "`r gsub('^0', '', format(Sys.Date(), '%d %B %Y'))`"
output:
    rmdformats::readthedown:
        fig_width: 8
        fig_height: 5
        thumbnails: false
        lightbox: true
        gallery: true
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(dev = "svg", message = FALSE)
```

# Binomial inference
In this problem we’ll study the binomial inference for a study that reports
$y = 7$ successes in $n = 20$ independent trials.
```{r}
y <- 7  # number of successes
n <- 20 # number of trials
```
We’ll assume three different priors:

* a uniform distribution
* a Jeffrey’s prior
* a step function defined as
$$
    g(\pi) =
    \begin{cases}
        \pi       &       \pi \leqslant 0.2 \\
        0.2       & 0.2 < \pi \leqslant 0.3 \\
        0.5 - \pi & 0.3 < \pi \leqslant 0.5 \\
        0         & 0.5 < \pi
    \end{cases}
$$

Let’s implement the step function first…
```{r}
stepf <- function(x) {
   ifelse(x <= 0.2, x,
          ifelse(x <= 0.3, 0.2,
                 ifelse(x <= 0.5, 0.5 - x, 0)))
}
```
… and compute the three posterior distributions. For the uniform and
Jeffrey's prior, this is straightforward since they are just beta
distributions, which are the conjugate prior for the binomial likelihood.
Thus, the posteriors are beta distributions with different $\alpha$ and
$\beta$ values depending on the exponents resulting from the product of the
likelihood and the prior.
```{r}
alph_unif <- 1 + y
beta_unif <- 1 + n - y
alph_jeff <- 0.5 + y
beta_jeff <- 0.5 + n - y

post_unif <- function(p) dbeta(p, alph_unif, beta_unif)
post_jeff <- function(p) dbeta(p, alph_jeff, beta_jeff)
```
For the case of the step function, we need to multiply the likelihood and
the step prior, and then perform numerical integration to determine the
normalization constant.
```{r}
post_step <- function(p) {
    post_step_num <- \(x) stepf(x) * dbinom(y, n, x)
    post_step_num(p) / integrate(post_step_num, 0, 1)$value
}
```
Let’s plot the three posteriors on top of each other to compare them.
```{r}
library(tidyverse)
theme_set(theme_light(base_size = 14, base_family = "Lato"))

# probability vector with step size dp
dp <- 1 / 2000
p <- seq(0, 1, by = dp)

posts <- tibble(
    p = p,
    unif = post_unif(p),
    jeff = post_jeff(p),
    step = post_step(p)
) |>
    # transform to long format for ggplot
    pivot_longer(-1, names_to = "dist", values_to = "fp") |>
    # reorder `dist` factors to follow the order in the text
    mutate(dist = fct_relevel(dist, "unif", "jeff", "step"))

prior_names <- c(unif = "Uniform", jeff = "Jeffrey’s", step = "Step")
# define color palette and map colours to prior names
my_pal <- c("#EE9C39", "#20A47B", "#5A3920")
prior_cols <- my_pal |> set_names("unif", "jeff", "step")

ggplot(posts, aes(x = p, y = fp, colour = dist)) +
    geom_line(linewidth = 0.8) +
    scale_colour_manual(values = prior_cols, labels = prior_names) +
    labs(x = "π", y = "g(π | y, n)", colour = "Prior") +
    # make plot start at (0, 0)
    coord_cartesian(expand = FALSE, ylim = c(0, 6))
```

To further the comparison, we can compute the first two moments of each 
posterior distribution.
```{r}
# define function for later use
moment <- function(dist, n) {
    # integrate each function in dist
    purrr::map_dbl(dist, \(f) integrate(\(p) p^n * f(p), 0, 1)$value)
}

means <- moment(c(post_unif, post_jeff, post_step), 1)
variances <- moment(c(post_unif, post_jeff, post_step), 2) - means^2
```

Now we’ll also compute a 95% credibility interval on each distribution.
For the uniform and Jeffrey’s it’s easy, we can use the built-in quantile
function `qbeta`. For the step function we have to find the probability
thresholds numerically.
```{r}
thresh <- c(0.025, 0.975)
creds <- list(
    unif = qbeta(thresh, alph_unif, beta_unif),
    jeff = qbeta(thresh, alph_jeff, beta_jeff),
    step = map_dbl(
        thresh,
        # compute the cdf and find the two p's close to 0.025, 0.975
        \(t) p[which(near(cumsum(post_step(p)) * dp, t, tol = dp / 2))]
    )
)
```

Let’s put the results in a summary table, and draw the limits on the
plot of the posterior distributions.
```{r}
# put table code into function for later use
summary_table <- function(prior_names, means, variances, creds) {
    tibble::tibble(prior_names, means, variances, creds) |>
        # format digits in every column
        dplyr::mutate(creds = format(creds, digits = 3)) |>
        dplyr::mutate_if(is.numeric, format, digits = 3) |>
        rlang::set_names("Prior", "Mean", "Variance", "95% cred. int.") |>
        kableExtra::kbl() |>
        kableExtra::kable_styling(full_width = FALSE)
}

summary_table(prior_names, means, variances, creds)
```
```{r}
ggplot(posts, aes(x = p, y = fp, colour = dist)) +
    geom_line(linewidth = 0.8) +
    # shade 95% credibility intervals
    geom_ribbon(
        aes(ymin = 0, ymax = fp, fill = dist),
        data = posts |>
            group_by(dist) |>
            # keep only the values inside the cred. int. for each dist
            filter(p > creds[[unique(dist)]][1] &
                   p < creds[[unique(dist)]][2]),
        alpha = 0.5,
        show.legend = FALSE
    ) +
    scale_colour_manual(values = prior_cols, labels = prior_names) +
    scale_fill_manual(values = prior_cols) +
    labs(x = "π", y = "g(π | y, n)", colour = "Prior") +
    coord_cartesian(expand = FALSE, ylim = c(0, 6))
```

# Giardia cysts
Giardia cysts are a parasite that can contaminate food, water and surfaces,
and they can cause *giardiasis* when swallowed in this infective stage of
their life cycle. Infection occurs when a person swallows Giardia cysts 
from contaminated water, food, hands, surfaces or objects.

A group of researchers from a Human Health Department is working to
determine the quality of stream water. They collect a total of 116
one-liter water samples from sites suspected to have a heavy environmental
impact from birds and water flow. Out of these samples, 17 contain Giardia
cysts.

We’ll find the posterior distribution for the probability $\pi$ that one
sample contains Giardia cysts, assuming

* a uniform prior distribution
* a $\operatorname{Beta}(1, 4)$ prior

Once again, we’re looking at a binomial process, so the posterior
distributions will be just two other beta distributions, with different
$\alpha$ and $\beta$ depending on $y$ and $n$.

```{r}
y <- 17
n <- 116

alph_unif <- 1 + y
beta_unif <- 1 + n - y
alph_beta <- 1 + y
beta_beta <- 4 + n - y

post_unif <- function(p) dbeta(p, alph_unif, beta_unif)
post_beta <- function(p) dbeta(p, alph_beta, beta_beta)
```

Let’s compute mean, variance and 95% credibility intervals for the two
posteriors, and display the results in a summary table and a plot. We’ll
also add a normal approximation for the posterior, based on 
```{r}
# use the function defined before on the new posteriors
means <- moment(c(post_unif, post_beta), 1)
variances <- moment(c(post_unif, post_beta), 2) - means^2

# cred. intervals are evaluated with quantile functions
creds <- list(
    unif = qbeta(thresh, alph_unif, beta_unif),
    beta = qbeta(thresh, alph_beta, beta_beta)
)

# redefine full names and colour names
prior_names <- c(unif = "Uniform", beta = "Beta(1, 4)")
prior_cols <- my_pal[1:2] |> set_names("unif", "beta")

# call the function that prints the table
summary_table(prior_names, means, variances, creds)
```
```{r}
# put data in long-format tibble, then plot
tibble(p = p, unif = post_unif(p), beta = post_beta(p)) |>
    pivot_longer(-1, names_to = "dist", values_to = "fp") |>
    mutate(dist = fct_relevel(dist, "unif", "beta")) |>
    ggplot(aes(x = p, y = fp, colour = dist)) +
        geom_line(linewidth = 0.8) +
        # shaded credibility intervals
        geom_ribbon(
            aes(ymin = 0, ymax = fp, fill = dist),
            data = function(x) {
                x |> group_by(dist) |>
                     filter(p > creds[[unique(dist)]][1] &
                            p < creds[[unique(dist)]][2])
            },
            alpha = 0.5,
            show.legend = FALSE
        ) +
        scale_colour_manual(values = prior_cols, labels = prior_names) +
        scale_fill_manual(values = prior_cols) +
        labs(x = "π", y = "g(π | y, n)", colour = "Prior") +
        coord_cartesian(expand = FALSE, ylim = c(0, 13.5)) +
        # fiddle with the axis breaks
        scale_y_continuous(breaks = scales::pretty_breaks())
```

Since we are working with quite a high number of samples, it’s sensible to
try approximating the two beta posteriors with normal PDFs. The expected 
value of a $X \sim \operatorname{Beta}(\alpha, \beta)$ is given by
$$
    \operatorname{E}(X) = \frac{\alpha}{\alpha + \beta},
$$
while the variance is
$$
    \operatorname{Var}(X) =
        \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}.
$$
So, we’ll calculate these two quantities for each `dbeta` and put the
results in a `dnorm` call.
```{r}
mu_unif <- alph_unif / (alph_unif + beta_unif)
sigma_unif <- sqrt(alph_unif * beta_unif
                   / ((alph_unif + beta_unif)^2
                      * (alph_unif + beta_unif + 1)))
mu_beta <- alph_beta / (alph_beta + beta_beta)
sigma_beta <- sqrt(alph_beta * beta_beta
                   / ((alph_beta + beta_beta)^2
                      * (alph_beta + beta_beta + 1)))

norm_unif <- function(p) dnorm(p, mu_unif, sigma_unif)
norm_beta <- function(p) dnorm(p, mu_beta, sigma_beta)
```

Let’s summarize the results in the usual table and plot.
```{r}
# credibility intervals
creds_n <- list(
    unif = list(
        orig = creds$unif,
        appr = qnorm(thresh, mu_unif, sigma_unif)
    ),
    beta = list(
        orig = creds$beta,
        appr = qnorm(thresh, mu_beta, sigma_beta)
    )
)

# summary table
# the means and variances are, by construction, the same as before
tibble(
    prior_names, means, variances, creds,
    creds_n = list(creds_n$unif$appr, creds_n$beta$appr)
) |>
    mutate(
        creds = format(creds, digits = 3),
        creds_n = format(creds_n, digits = 3)
    ) |>
    mutate_if(is.numeric, format, digits = 3) |>
    set_names(
        "Prior", "Mean", "Variance",
        "95% cred. int.", "95% cred. int. (normal appr.)"
    ) |>
    kableExtra::kbl() |>
    kableExtra::kable_styling(full_width = FALSE)
```
```{r}
# choose some new colours to distinguish original/approximation
type_cols <- c(orig = "#ac2941", appr = "#5aa4cd")
# make a new dataset with the new functions
tibble(
    p = p,
    unif = post_unif(p),
    unif_n = norm_unif(p),
    beta = post_beta(p),
    beta_n = norm_beta(p),
) |>
    pivot_longer(-1, names_to = "dist", values_to = "fp") |>
    # encode the original/approximation distinction in separate column
    mutate(
        type = ifelse(str_ends(dist, "_n"), "appr", "orig"),
        dist = str_remove(dist, "_n")
    ) |>
    # reorder factors as needed
    mutate(
        dist = fct_relevel(dist, "unif", "beta"),
        type = fct_relevel(type, "orig", "appr")
    ) |>
    ggplot(aes(x = p, y = fp, colour = type)) +
        geom_line(linewidth = 0.8) +
        geom_ribbon(
            aes(ymin = 0, ymax = fp, fill = type),
            data = function(x) {
                # group and filter
                x |>
                    group_by(dist, type) |>
                    filter(p > creds_n[[unique(dist)]][[unique(type)]][1] &
                           p < creds_n[[unique(dist)]][[unique(type)]][2])
            },
            alpha = 0.5,
            show.legend = FALSE
        ) +
        scale_colour_manual(
            values = type_cols, labels = c("Original", "Normal appr.")
        ) +
        scale_fill_manual(values = type_cols) +
        labs(x = "π", y = "g(π | y, n)", colour = "Type") +
        coord_cartesian(expand = FALSE, ylim = c(0, 13.5)) +
        scale_y_continuous(breaks = scales::pretty_breaks()) +
        facet_grid(
            rows = vars(dist),
            labeller = as_labeller(
                c(unif = "Uniform prior", beta = "Beta(1, 4) prior")
            )
        )
```

# Coin flipping
A coin is flipped 30 times with the following outcomes:
```
    T, T, T, T, T, H, T, T, H, H,
    T, T, H, H, H, T, H, T, H, T,
    H, H, T, H, T, H, T, H, H, H
```

We’ll assume a flat prior and a $\operatorname{Beta}(10, 10)$ prior, and
plot the likelihood, prior and posterior distributions following the two
assumptions.
```{r}
results <- c(
    "T", "T", "T", "T", "T", "H", "T", "T", "H", "H",
    "T", "T", "H", "H", "H", "T", "H", "T", "H", "T",
    "H", "H", "T", "H", "T", "H", "T", "H", "H", "H"
)

n <- length(results)     # total throws
h <- sum(results == "H") # number of heads

# likelihood
lhood <- function(p) {
    dbinom(h, n, p) / integrate(\(x) dbinom(h, n, x), 0, 1)$value
}

# beta prior parameters
a <- 10
b <- 10

# priors
prior_flat <- function(p) dunif(p, 0, 1)
prior_beta <- function(p) dbeta(p, a, b)

# posterior parameters
alph_flat <- 1 + h
beta_flat <- 1 + n - h
alph_beta <- a + h
beta_beta <- b + n - h

# posteriors
post_flat <- function(p) dbeta(p, alph_flat, beta_flat)
post_beta <- function(p) dbeta(p, alph_beta, beta_beta)
```

```{r}
# define palette
dist_cols <- my_pal |> set_names("lik", "pri", "pos")
dist_names <- c(lik = "Likelihood", pri = "Prior", pos = "Posterior")

tibble(
    p = p,
    # duplicate the likelihood to help facet_grid later
    flat_lik = lhood(p),
    flat_pri = prior_flat(p),
    flat_pos = post_flat(p),
    beta_lik = lhood(p),
    beta_pri = prior_beta(p),
    beta_pos = post_beta(p)
) |>
    pivot_longer(-1, names_to = "prior", values_to = "fp") |>
    # move lik/pri/pos indicator to `dist` column
    # keep only flat/beta indicator in `prior` column
    mutate(dist = str_sub(prior, -3), prior = str_sub(prior, 1, 4)) |>
    mutate(
        dist = fct_relevel(dist, "lik", "pri", "pos"),
        prior = fct_relevel(prior, "flat", "beta")
    ) |>
    ggplot(aes(x = p, y = fp, colour = dist)) +
        geom_line(linewidth = 0.8) +
        scale_colour_manual(values = dist_cols, labels = dist_names) +
        scale_fill_manual(values = dist_cols) +
        labs(x = "π", y = "f(π)", colour = "Distribution") +
        coord_cartesian(expand = FALSE, ylim = c(0, 6)) +
        facet_grid(
            rows = vars(prior),
            labeller = as_labeller(
                c(flat = "Flat prior", beta = "Beta(10, 10) prior")
            )
        )
```